{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OCR Pipeline for Handwritten Document PII Extraction\n",
        "\n",
        "This notebook implements an end-to-end pipeline:\n",
        "1. Image Pre-processing\n",
        "2. OCR (Optical Character Recognition)\n",
        "3. Text Cleaning\n",
        "4. PII Detection\n",
        "5. Optional: Redacted Image Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import easyocr\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Optional\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Image Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image_path: str, return_binary: bool = False) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Pre-process image for better OCR results.\n",
        "    Handles: rotation correction, noise reduction, contrast enhancement\n",
        "    \n",
        "    For handwritten text, grayscale often works better than binary.\n",
        "    \"\"\"\n",
        "    # Read image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not read image: {image_path}\")\n",
        "    \n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Deskew (correct rotation)\n",
        "    gray = deskew_image(gray)\n",
        "    \n",
        "    # Denoise - use lighter denoising for handwritten text\n",
        "    denoised = cv2.fastNlMeansDenoising(gray, None, 5, 7, 21)  # Reduced h from 10 to 5\n",
        "    \n",
        "    # Enhance contrast using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))  # Slightly higher clipLimit\n",
        "    enhanced = clahe.apply(denoised)\n",
        "    \n",
        "    if return_binary:\n",
        "        # Threshold to binary (black and white) - only if specifically requested\n",
        "        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        return binary\n",
        "    \n",
        "    # Return enhanced grayscale (better for handwritten text)\n",
        "    return enhanced\n",
        "\n",
        "def deskew_image(image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Correct slight rotation/tilt in the image.\n",
        "    \"\"\"\n",
        "    # Find all non-zero points\n",
        "    coords = np.column_stack(np.where(image > 0))\n",
        "    \n",
        "    if len(coords) == 0:\n",
        "        return image\n",
        "    \n",
        "    # Find minimum area rectangle\n",
        "    angle = cv2.minAreaRect(coords)[-1]\n",
        "    \n",
        "    # Correct angle\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = -angle\n",
        "    \n",
        "    # Only rotate if angle is significant (> 0.5 degrees)\n",
        "    if abs(angle) > 0.5:\n",
        "        (h, w) = image.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "        return rotated\n",
        "    \n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. OCR Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize EasyOCR reader (supports handwritten text)\n",
        "# This will download models on first run\n",
        "print(\"Initializing EasyOCR (this may take a moment on first run)...\")\n",
        "reader = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
        "print(\"EasyOCR initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_ocr(image: np.ndarray, use_binary: bool = False) -> tuple:\n",
        "    \"\"\"\n",
        "    Perform OCR on preprocessed image.\n",
        "    For handwritten text, using grayscale often works better than binary.\n",
        "    Returns raw extracted text and OCR results.\n",
        "    \"\"\"\n",
        "    # For handwritten text, use grayscale\n",
        "    if use_binary:\n",
        "        ocr_image = image\n",
        "    else:\n",
        "        # Convert binary back to grayscale if needed, or use original grayscale\n",
        "        if len(image.shape) == 2:\n",
        "            ocr_image = image\n",
        "        else:\n",
        "            ocr_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # For handwritten text, use more lenient parameters to get more text\n",
        "    results = reader.readtext(\n",
        "        ocr_image,\n",
        "        paragraph=False,  # Don't group - get individual detections\n",
        "        width_ths=0.5,     # Even lower threshold for width (handwritten is variable)\n",
        "        height_ths=0.5,    # Even lower threshold for height\n",
        "        detail=1,          # Return detailed results\n",
        "        allowlist=None,    # Allow all characters\n",
        "        blocklist=''       # Don't block any characters\n",
        "    )\n",
        "    \n",
        "    # Combine all detected text\n",
        "    text_lines = []\n",
        "    for result in results:\n",
        "        # Handle both tuple and list formats\n",
        "        if isinstance(result, (tuple, list)) and len(result) >= 3:\n",
        "            bbox, text, confidence = result[0], result[1], result[2]\n",
        "            # Very low confidence threshold for handwritten text\n",
        "            if confidence > 0.1:  # Very low threshold to capture more text\n",
        "                text_lines.append(text)\n",
        "    \n",
        "    # Join text blocks\n",
        "    if text_lines:\n",
        "        raw_text = ' '.join(text_lines)  # Join with spaces\n",
        "    else:\n",
        "        raw_text = ''\n",
        "    \n",
        "    return raw_text, results  # Return both text and bbox info for redaction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Text Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean and normalize extracted text.\n",
        "    \"\"\"\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # Remove special characters that are OCR artifacts\n",
        "    text = re.sub(r\"[^\\w\\s\\.,;:!?\\-'\\\"()\\[\\]{}@#%&*+=/\\\\]\", '', text)\n",
        "    \n",
        "    # Fix common OCR errors\n",
        "    replacements = {\n",
        "        r'\\b0\\b': 'O',  # Standalone 0 might be O\n",
        "        r'\\bl\\b': 'I',  # Standalone l might be I\n",
        "    }\n",
        "    \n",
        "    # Normalize line breaks\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PII Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_pii(text: str) -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Detect Personally Identifiable Information (PII) in text.\n",
        "    Returns dictionary with PII types and detected values.\n",
        "    \"\"\"\n",
        "    pii = {\n",
        "        'emails': [],\n",
        "        'phone_numbers': [],\n",
        "        'ssn': [],\n",
        "        'dates': [],\n",
        "        'names': [],  # Basic name detection (capitalized words, 2-3 words)\n",
        "        'addresses': [],\n",
        "        'medical_record_numbers': [],\n",
        "        'dates_of_birth': []\n",
        "    }\n",
        "    \n",
        "    # Email pattern\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "    pii['emails'] = re.findall(email_pattern, text, re.IGNORECASE)\n",
        "    \n",
        "    # Phone numbers (various formats)\n",
        "    phone_patterns = [\n",
        "        r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b',  # 123-456-7890\n",
        "        r'\\b\\(\\d{3}\\)\\s?\\d{3}[-.]?\\d{4}\\b',  # (123) 456-7890\n",
        "        r'\\b\\d{10}\\b'  # 1234567890\n",
        "    ]\n",
        "    for pattern in phone_patterns:\n",
        "        matches = re.findall(pattern, text)\n",
        "        pii['phone_numbers'].extend(matches)\n",
        "    pii['phone_numbers'] = list(set(pii['phone_numbers']))  # Remove duplicates\n",
        "    \n",
        "    # SSN pattern\n",
        "    ssn_pattern = r'\\b\\d{3}-?\\d{2}-?\\d{4}\\b'\n",
        "    pii['ssn'] = re.findall(ssn_pattern, text)\n",
        "    \n",
        "    # Dates (MM/DD/YYYY, DD/MM/YYYY, etc.)\n",
        "    date_patterns = [\n",
        "        r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b',  # 01/15/2024 or 1/15/24\n",
        "        r'\\b\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}\\b',  # 2024/01/15\n",
        "        r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{1,2},?\\s+\\d{4}\\b',  # January 15, 2024\n",
        "    ]\n",
        "    for pattern in date_patterns:\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        pii['dates'].extend(matches)\n",
        "    pii['dates'] = list(set(pii['dates']))\n",
        "    \n",
        "    # Date of Birth (DOB) - look for keywords\n",
        "    dob_keywords = r'\\b(?:DOB|Date of Birth|Born|Birth Date)[: ]*([\\d/\\-]+|[A-Za-z]+\\s+\\d{1,2},?\\s+\\d{4})\\b'\n",
        "    dob_matches = re.findall(dob_keywords, text, re.IGNORECASE)\n",
        "    pii['dates_of_birth'] = dob_matches\n",
        "    \n",
        "    # Medical Record Number (MRN) - various formats\n",
        "    mrn_patterns = [\n",
        "        r'\\bMRN[: ]*([A-Z0-9]{6,12})\\b',\n",
        "        r'\\bMedical Record[: ]*([A-Z0-9]{6,12})\\b',\n",
        "        r'\\bRecord #[: ]*([A-Z0-9]{6,12})\\b'\n",
        "    ]\n",
        "    for pattern in mrn_patterns:\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        pii['medical_record_numbers'].extend(matches)\n",
        "    pii['medical_record_numbers'] = list(set(pii['medical_record_numbers']))\n",
        "    \n",
        "    # Names - simple heuristic: capitalized 2-3 word sequences\n",
        "    # This is basic - could be improved with NER models\n",
        "    name_pattern = r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,2}\\b'\n",
        "    potential_names = re.findall(name_pattern, text)\n",
        "    # Filter out common false positives\n",
        "    false_positives = {'Date', 'Time', 'Name', 'Address', 'Phone', 'Email', 'Patient', 'Doctor', 'Clinic', 'Hospital'}\n",
        "    pii['names'] = [name for name in potential_names if not any(fp in name for fp in false_positives)]\n",
        "    \n",
        "    # Addresses - look for street patterns\n",
        "    address_pattern = r'\\b\\d+\\s+[A-Z][a-z]+\\s+(?:Street|St|Avenue|Ave|Road|Rd|Drive|Dr|Lane|Ln|Boulevard|Blvd|Court|Ct|Place|Pl)\\b'\n",
        "    pii['addresses'] = re.findall(address_pattern, text, re.IGNORECASE)\n",
        "    \n",
        "    # Remove empty categories\n",
        "    pii = {k: v for k, v in pii.items() if v}\n",
        "    \n",
        "    return pii\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Redaction (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_redacted_image(image_path: str, ocr_results: List, pii_texts: List[str], output_path: str):\n",
        "    \"\"\"\n",
        "    Create a redacted version of the image by blacking out PII regions.\n",
        "    \"\"\"\n",
        "    # Load original image\n",
        "    img = cv2.imread(image_path)\n",
        "    \n",
        "    # Convert PII texts to lowercase for matching\n",
        "    pii_lower = [p.lower() for p in pii_texts]\n",
        "    \n",
        "    # Find and redact bounding boxes containing PII\n",
        "    for result in ocr_results:\n",
        "        # Handle both tuple and list formats\n",
        "        if isinstance(result, (tuple, list)) and len(result) >= 3:\n",
        "            bbox, text, confidence = result[0], result[1], result[2]\n",
        "            text_lower = text.lower()\n",
        "            # Check if this text contains any PII\n",
        "            if any(pii in text_lower for pii in pii_lower):\n",
        "                # Get bounding box coordinates\n",
        "                bbox = np.array(bbox, dtype=np.int32)\n",
        "                # Draw black rectangle over the text\n",
        "                cv2.fillPoly(img, [bbox], (0, 0, 0))\n",
        "    \n",
        "    # Save redacted image\n",
        "    cv2.imwrite(output_path, img)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell intentionally left blank - redaction function is defined above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Main Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_document(image_path: str, create_redaction: bool = True) -> Dict:\n",
        "    \"\"\"\n",
        "    Complete pipeline: Pre-process → OCR → Clean → PII Detection → Redaction\n",
        "    \"\"\"\n",
        "    print(f\"Processing: {image_path}\")\n",
        "    \n",
        "    # Step 1: Pre-processing\n",
        "    print(\"Step 1: Pre-processing image...\")\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    \n",
        "    # Step 2: OCR\n",
        "    print(\"Step 2: Performing OCR...\")\n",
        "    raw_text, ocr_results = perform_ocr(processed_img)\n",
        "    \n",
        "    # Step 3: Text Cleaning\n",
        "    print(\"Step 3: Cleaning text...\")\n",
        "    cleaned_text = clean_text(raw_text)\n",
        "    \n",
        "    # Step 4: PII Detection\n",
        "    print(\"Step 4: Detecting PII...\")\n",
        "    pii_detected = detect_pii(cleaned_text)\n",
        "    \n",
        "    # Step 5: Optional Redaction\n",
        "    redacted_path = None\n",
        "    if create_redaction:\n",
        "        print(\"Step 5: Creating redacted image...\")\n",
        "        # Collect all PII text for redaction\n",
        "        all_pii_texts = []\n",
        "        for pii_list in pii_detected.values():\n",
        "            all_pii_texts.extend(pii_list)\n",
        "        \n",
        "        if all_pii_texts:\n",
        "            base_name = Path(image_path).stem\n",
        "            output_dir = Path(image_path).parent / 'output'\n",
        "            output_dir.mkdir(exist_ok=True)\n",
        "            redacted_path = str(output_dir / f\"{base_name}_redacted.jpg\")\n",
        "            create_redacted_image(image_path, ocr_results, all_pii_texts, redacted_path)\n",
        "    \n",
        "    # Compile results\n",
        "    results = {\n",
        "        'image_path': image_path,\n",
        "        'raw_text': raw_text,\n",
        "        'cleaned_text': cleaned_text,\n",
        "        'pii_detected': pii_detected,\n",
        "        'redacted_image_path': redacted_path\n",
        "    }\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Process Sample Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up paths\n",
        "samples_dir = Path('samples')\n",
        "output_dir = Path('output')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Find all JPEG images in samples folder\n",
        "image_files = list(samples_dir.glob('*.jpg')) + list(samples_dir.glob('*.jpeg')) + list(samples_dir.glob('*.JPG')) + list(samples_dir.glob('*.JPEG'))\n",
        "\n",
        "if not image_files:\n",
        "    print(\"No images found in 'samples' folder. Please add your JPEG images there.\")\n",
        "else:\n",
        "    print(f\"Found {len(image_files)} image(s) to process.\")\n",
        "    \n",
        "    # Process each image\n",
        "    all_results = []\n",
        "    for img_path in image_files:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        results = process_document(str(img_path), create_redaction=True)\n",
        "        all_results.append(results)\n",
        "        \n",
        "        # Display results\n",
        "        print(f\"\\nResults for {img_path.name}:\")\n",
        "        print(f\"\\nRaw Text:\\n{results['raw_text']}\")\n",
        "        print(f\"\\nCleaned Text:\\n{results['cleaned_text']}\")\n",
        "        print(f\"\\nPII Detected:\")\n",
        "        for pii_type, values in results['pii_detected'].items():\n",
        "            print(f\"  {pii_type}: {values}\")\n",
        "        \n",
        "        if results['redacted_image_path']:\n",
        "            print(f\"\\nRedacted image saved to: {results['redacted_image_path']}\")\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results to JSON\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all results to JSON file\n",
        "if all_results:\n",
        "    results_file = output_dir / 'results.json'\n",
        "    \n",
        "    # Convert Path objects to strings for JSON serialization\n",
        "    json_results = []\n",
        "    for r in all_results:\n",
        "        json_r = {\n",
        "            'image_path': str(r['image_path']),\n",
        "            'raw_text': r['raw_text'],\n",
        "            'cleaned_text': r['cleaned_text'],\n",
        "            'pii_detected': r['pii_detected'],\n",
        "            'redacted_image_path': str(r['redacted_image_path']) if r['redacted_image_path'] else None\n",
        "        }\n",
        "        json_results.append(json_r)\n",
        "    \n",
        "    with open(results_file, 'w') as f:\n",
        "        json.dump(json_results, f, indent=2)\n",
        "    \n",
        "    print(f\"\\nResults saved to: {results_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Display Images (for visualization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Display original and redacted images side by side\n",
        "if all_results:\n",
        "    for result in all_results:\n",
        "        if result['redacted_image_path']:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
        "            \n",
        "            # Original\n",
        "            orig_img = cv2.imread(result['image_path'])\n",
        "            orig_img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
        "            axes[0].imshow(orig_img_rgb)\n",
        "            axes[0].set_title('Original Image')\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            # Redacted\n",
        "            redacted_img = cv2.imread(result['redacted_image_path'])\n",
        "            redacted_img_rgb = cv2.cvtColor(redacted_img, cv2.COLOR_BGR2RGB)\n",
        "            axes[1].imshow(redacted_img_rgb)\n",
        "            axes[1].set_title('Redacted Image')\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            print(f\"\\nPII Summary for {Path(result['image_path']).name}:\")\n",
        "            print(json.dumps(result['pii_detected'], indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
